{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUxBCR5n7LtQ",
    "outputId": "4601ccda-df7e-4569-92fe-7059ca981d51"
   },
   "outputs": [],
   "source": [
    "#!pip install llama-index-embeddings-huggingface\n",
    "#!pip install torch sentence-transformers\n",
    "#!pip install llama_index\n",
    "#!pip install tensorflow-io\n",
    "#!pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5FRgykT7TIx",
    "outputId": "f1285bfe-be6a-4016-d3a3-d6e202249a51"
   },
   "outputs": [],
   "source": [
    "#!pip install 'elasticsearch<7.14.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Rrgn8RC7ZER",
    "outputId": "3f83a97c-fb5b-4080-ebf3-37a4f906af98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from llama_index.core import Document\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GjYcOLe__w8C"
   },
   "outputs": [],
   "source": [
    "# Импорт библиотек TensorFlow и TensorFlow I/O\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "# Импорт дополнительных модулей из TensorFlow\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EAPKRNM3AGIp",
    "outputId": "8a3fa08c-e465-4f43-b24e-c111d88a4c5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticsearch-oss-7.10.0-linux-x86_64.tar.gz: OK\n"
     ]
    }
   ],
   "source": [
    "# Скачивание и распаковка Elasticsearch\n",
    "%%bash\n",
    "\n",
    "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.10.0-linux-x86_64.tar.gz\n",
    "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.10.0-linux-x86_64.tar.gz.sha512\n",
    "tar -xzf elasticsearch-oss-7.10.0-linux-x86_64.tar.gz\n",
    "sudo chown -R daemon:daemon elasticsearch-7.10.0/\n",
    "shasum -a 512 -c elasticsearch-oss-7.10.0-linux-x86_64.tar.gz.sha512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AXBegrGNc7j_"
   },
   "outputs": [],
   "source": [
    "# Запуск Elasticsearch в фоновом режиме\n",
    "%%bash --bg\n",
    "\n",
    "sudo -H -u daemon elasticsearch-7.10.0/bin/elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kiNRKVHNc-2g"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqGkSezR_xEr",
    "outputId": "3f85eb8f-d00f-4423-c068-48b9511dbb77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root       33719   33717  0 06:28 ?        00:00:00 sudo -H -u daemon elasticsearch-7.10.0/bin/elast\n",
      "daemon     33720   33719 78 06:28 ?        00:00:23 /content/elasticsearch-7.10.0/jdk/bin/java -Xsha\n",
      "root       34038   34036  0 06:29 ?        00:00:00 grep elasticsearch\n"
     ]
    }
   ],
   "source": [
    "# Проверка запущенных процессов Elasticsearch\n",
    "%%bash\n",
    "\n",
    "ps -ef | grep elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E3iLr26dASG6",
    "outputId": "38c085e2-697b-4106-d553-678d18a7c5bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"9dda0200f192\",\n",
      "  \"cluster_name\" : \"elasticsearch\",\n",
      "  \"cluster_uuid\" : \"RGWmq7oITz2ZwIdygJuRLw\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"7.10.0\",\n",
      "    \"build_flavor\" : \"oss\",\n",
      "    \"build_type\" : \"tar\",\n",
      "    \"build_hash\" : \"51e9d6f22758d0374a0f3f5c6e8f3a7997850f96\",\n",
      "    \"build_date\" : \"2020-11-09T21:30:33.964949Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"8.7.0\",\n",
      "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Проверка соединения с Elasticsearch\n",
    "%%bash\n",
    "\n",
    "curl -sX GET \"localhost:9200/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Luze09xMASKx",
    "outputId": "baf8b5e0-f9d4-4f43-a92d-946127981e4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание объекта Elasticsearch, подключенный к локальному экземпляру Elasticsearch,\n",
    "# который запущен на порту 9200 по протоколу HTTP\n",
    "es = Elasticsearch(hosts=[{\"host\": \"localhost\", \"port\": 9200, \"scheme\": \"http\"}])\n",
    "es.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grPiDqc97kS-"
   },
   "outputs": [],
   "source": [
    "# Загрузка модели для векторных представлений\n",
    "embed_model = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "# Загрузка модели для генерации ответов\n",
    "model = 'IlyaGusev/saiga_mistral_7b_lora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Q6wWv-cE7wF3"
   },
   "outputs": [],
   "source": [
    "# Функция для генерации ответов\n",
    "def generate_response(question):\n",
    "    inputs = tokenizer.encode(question, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_length=150, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YVeZ-Hqz77CP"
   },
   "outputs": [],
   "source": [
    "# Загрузка и индексация статей\n",
    "def index_articles(articles_path):\n",
    "    with open(articles_path, 'r', encoding='utf-8') as file:\n",
    "        articles = json.load(file)['pages']\n",
    "\n",
    "    # Создание индекса в Elasticsearch, если он не существует\n",
    "    if not es.indices.exists(index=\"articles\"):\n",
    "        es_index = {\n",
    "            \"settings\": {\n",
    "                \"index\": {\n",
    "                    \"number_of_shards\": 1,\n",
    "                    \"number_of_replicas\": 0\n",
    "                }\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"title\": {\"type\": \"text\"},\n",
    "                    \"text\": {\"type\": \"text\"},\n",
    "                    \"link\": {\"type\": \"keyword\"},\n",
    "                    \"text_vector\": {\"type\": \"dense_vector\", \"dims\": 512}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        es.indices.create(index=\"articles\", body=es_index)\n",
    "\n",
    "    # Индексация статей в Elasticsearch\n",
    "    for article in articles:\n",
    "        text_vector = embed_model.encode(article['text'])\n",
    "        doc = {\n",
    "            \"title\": article['title'],\n",
    "            \"text\": article['text'],\n",
    "            \"link\": article['link'],\n",
    "            \"text_vector\": text_vector\n",
    "        }\n",
    "        es.index(index=\"articles\", body=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LI78wXhr541N"
   },
   "outputs": [],
   "source": [
    "# Функция для интерактивного поиска и генерации ответов\n",
    "def interactive_search():\n",
    "    while True:\n",
    "        inp_question = input(\"Пожалуйста, введите вопрос: \")\n",
    "\n",
    "        # Вычисление векторного представления вопроса\n",
    "        encode_start_time = time.time()\n",
    "        question_embedding = embed_model.encode(inp_question)\n",
    "        encode_end_time = time.time()\n",
    "\n",
    "        # Лексический поиск с использованием TF-IDF\n",
    "        tfidf_search = es.search(index=\"articles\", body={\n",
    "            \"query\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": inp_question,\n",
    "                    \"fields\": [\"title\", \"text\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "        # Семантический поиск с использованием векторных представлений\n",
    "        sem_search = es.search(\n",
    "            index=\"articles\",\n",
    "            body={\n",
    "                \"query\": {\n",
    "                    \"script_score\": {\n",
    "                        \"query\": {\"match_all\": {}},\n",
    "                        \"script\": {\n",
    "                            \"source\": \"cosineSimilarity(params.query_vector, 'text_vector') + 1.0\",\n",
    "                            \"params\": {\"query_vector\": question_embedding.tolist()}\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Вывод результатов поиска и времени выполнения\n",
    "        print(\"Введенный вопрос:\", inp_question)\n",
    "        print(\n",
    "            \"Вычисление эмбеддинга заняло {:.3f} секунд, поиск по TF-IDF занял {:.3f} секунд, семантический поиск с ES занял {:.3f} секунд\".format(\n",
    "                encode_end_time - encode_start_time, tfidf_search[\"took\"] / 1000, sem_search[\"took\"] / 1000\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\"Результаты поиска по TF-IDF:\")\n",
    "        for hit in tfidf_search[\"hits\"][\"hits\"][0:5]:\n",
    "            print(\"\\t{}\".format(hit[\"_source\"][\"text\"]))\n",
    "            print(\"\\tСсылка: {}\".format(hit[\"_source\"][\"link\"]))\n",
    "\n",
    "        print(\"\\nРезультаты семантического поиска:\")\n",
    "        for hit in sem_search[\"hits\"][\"hits\"][0:5]:\n",
    "            print(\"\\t{}\".format(hit[\"_source\"][\"text\"]))\n",
    "            print(\"\\tСсылка: {}\".format(hit[\"_source\"][\"link\"]))\n",
    "\n",
    "        # Генерация ответа на вопрос\n",
    "        response = generate_response(inp_question)\n",
    "        print(\"\\nОтвет от модели SaigaMistral:\")\n",
    "        print(response)\n",
    "\n",
    "        print(\"\\n\\n========\\n\")\n",
    "\n",
    "# Основная функция\n",
    "if __name__ == \"__main__\":\n",
    "    articles_path = \"/content/ConfluencePages.json\"\n",
    "    index_articles(articles_path)\n",
    "    interactive_search()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
